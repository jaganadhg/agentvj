{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Optional, Union, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DummyLLM:\n",
    "    \"\"\"\n",
    "    A dummy LLM implementation that returns random responses\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, temperature: float = 0.7):\n",
    "        self.temperature = temperature\n",
    "        self._responses = [\n",
    "            \"I think we should use the calculator tool for this task.\",\n",
    "            \"Let me search through the available tools.\",\n",
    "            \"Based on my analysis, we should proceed step by step.\",\n",
    "            \"I recommend using the following approach...\",\n",
    "            \"The solution requires mathematical computation.\",\n",
    "            \"Let's break this problem down into smaller parts.\",\n",
    "        ]\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        system_message: Optional[str] = None,\n",
    "        temperature: Optional[float] = None,\n",
    "    ) -> Dict[str, Union[str, float]]:\n",
    "        \"\"\"\n",
    "        Generate a random response with metadata\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The input prompt\n",
    "            system_message (Optional[str]): System message to guide generation\n",
    "            temperature (Optional[float]): Override default temperature\n",
    "\n",
    "        Returns:\n",
    "            Dict containing response text and metadata\n",
    "        \"\"\"\n",
    "        # Use random confidence score between 0.3 and 0.9\n",
    "        confidence = random.uniform(0.3, 0.9)\n",
    "\n",
    "        return {\n",
    "            \"text\": random.choice(self._responses),\n",
    "            \"confidence\": confidence,\n",
    "            \"tokens_used\": random.randint(10, 50),\n",
    "            \"finish_reason\": \"stop\",\n",
    "        }\n",
    "\n",
    "    def batch_generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        system_message: Optional[str] = None,\n",
    "        temperature: Optional[float] = None,\n",
    "    ) -> List[Dict[str, Union[str, float]]]:\n",
    "        \"\"\"\n",
    "        Generate multiple random responses\n",
    "\n",
    "        Args:\n",
    "            prompts (List[str]): List of input prompts\n",
    "            system_message (Optional[str]): System message to guide generation\n",
    "            temperature (Optional[float]): Override default temperature\n",
    "\n",
    "        Returns:\n",
    "            List of response dictionaries\n",
    "        \"\"\"\n",
    "        return [\n",
    "            self.generate(prompt, system_message, temperature) for prompt in prompts\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
