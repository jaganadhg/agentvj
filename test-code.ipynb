{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Optional, Union, Dict, List,Any\n",
    "import json\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vj.agents.core import BaseAgent,AgentError\n",
    "from vj.tools.tool import Tool\n",
    "from vj.agents.templates import ReactAgentTemplate\n",
    "from vj.tools.tool import CalculatorTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    React Agent implementation following thought-action-observation cycle\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tools: List[Tool],\n",
    "        model: callable,\n",
    "        max_steps: int = 10,\n",
    "        template: Optional[ReactAgentTemplate] = None,\n",
    "        temperature: float = 0.7,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            tools=tools,\n",
    "            model=model,\n",
    "            max_steps=max_steps,\n",
    "            name=\"react_agent\",\n",
    "            description=\"A React-style agent that follows thought-observation-action cycle\",\n",
    "        )\n",
    "        self.template = template or ReactAgentTemplate()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def generate_action(self, task: str) -> dict:\n",
    "        \"\"\"\n",
    "        Generate next action based on thought process\n",
    "\n",
    "        Args:\n",
    "            task (str): The current task\n",
    "\n",
    "        Returns:\n",
    "            dict: Action dictionary with tool and input\n",
    "        \"\"\"\n",
    "        # Format history and create prompt\n",
    "        history = self._format_history()\n",
    "\n",
    "        # Create system message\n",
    "        system_prompt = (\n",
    "            self.template.DEFAULT_TEMPLATE.split(\"[prompts]\")[1]\n",
    "            .split(\"system = '''\")[1]\n",
    "            .split(\"'''\")[0]\n",
    "        )\n",
    "\n",
    "        # Build prompt with task and history\n",
    "        prompt = f\"\"\"\n",
    "        Task: {task}\n",
    "        Previous Steps: {history}\n",
    "        Current Step: {self.current_step + 1}\n",
    "\n",
    "        Think through this step by step. Available tools:\n",
    "        {self._format_tools()}\n",
    "\n",
    "        Respond with:\n",
    "        Thought: [your reasoning]\n",
    "        Action: [tool_name] [parameters]\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate response\n",
    "        response = self.model(system_prompt, prompt, temperature=self.temperature)\n",
    "\n",
    "        # Parse response to extract action\n",
    "        try:\n",
    "            # Extract action from response\n",
    "            thought, action = \"\", \"\"\n",
    "\n",
    "            if \"Thought:\" in response:\n",
    "                thought_parts = (\n",
    "                    response.split(\"Thought:\")[1].split(\"Action:\")[0].strip()\n",
    "                )\n",
    "                thought = thought_parts\n",
    "\n",
    "            if \"Action:\" in response:\n",
    "                action_parts = response.split(\"Action:\")[1].strip().split()\n",
    "                if len(action_parts) >= 2:\n",
    "                    tool_name = action_parts[0]\n",
    "                    tool_input = \" \".join(action_parts[1:])\n",
    "\n",
    "                    return {\"thought\": thought, \"tool\": tool_name, \"input\": tool_input}\n",
    "\n",
    "            raise AgentError(\"Failed to parse action from response\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to generate action: {str(e)}\")\n",
    "            raise AgentError(f\"Action generation failed: {str(e)}\")\n",
    "\n",
    "    def execute_action(self, action: dict) -> Any:\n",
    "        \"\"\"\n",
    "        Execute the generated action using available tools\n",
    "\n",
    "        Args:\n",
    "            action (dict): Action dictionary with tool and input\n",
    "\n",
    "        Returns:\n",
    "            Any: Result of tool execution\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tool_name = action[\"tool\"]\n",
    "            tool_input = action[\"input\"]\n",
    "\n",
    "            if tool_name == \"final_answer\":\n",
    "                return {\"observation\": tool_input, \"status\": \"final_answer\"}\n",
    "\n",
    "            if tool_name not in self.tools:\n",
    "                return {\n",
    "                    \"observation\": f\"Error: Unknown tool '{tool_name}'\",\n",
    "                    \"status\": \"error\",\n",
    "                }\n",
    "\n",
    "            tool = self.tools[tool_name]\n",
    "            result = tool.execute(tool_input)\n",
    "\n",
    "            return {\"observation\": str(result), \"status\": \"success\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Action execution failed: {str(e)}\")\n",
    "            return {\"observation\": f\"Error: {str(e)}\", \"status\": \"error\"}\n",
    "\n",
    "    def is_final_answer(self, result: Any) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the result is a final answer\n",
    "\n",
    "        Args:\n",
    "            result (Any): The action execution result\n",
    "\n",
    "        Returns:\n",
    "            bool: True if this is the final answer\n",
    "        \"\"\"\n",
    "        if isinstance(result, dict) and \"status\" in result:\n",
    "            return result[\"status\"] == \"final_answer\"\n",
    "        return False\n",
    "\n",
    "    def _format_history(self) -> str:\n",
    "        \"\"\"Format the agent's memory into a string\"\"\"\n",
    "        if not self.memory.steps:\n",
    "            return \"No previous actions\"\n",
    "\n",
    "        history = []\n",
    "        for step in self.memory.steps:\n",
    "            action = step[\"action\"]\n",
    "            result = step[\"result\"]\n",
    "\n",
    "            thought = action.get(\"thought\", \"\")\n",
    "            tool = action.get(\"tool\", \"\")\n",
    "            tool_input = action.get(\"input\", \"\")\n",
    "\n",
    "            observation = (\n",
    "                result.get(\"observation\", \"\")\n",
    "                if isinstance(result, dict)\n",
    "                else str(result)\n",
    "            )\n",
    "\n",
    "            history.append(f\"Step {step['step'] + 1}:\")\n",
    "            history.append(f\"Thought: {thought}\")\n",
    "            history.append(f\"Action: {tool} {tool_input}\")\n",
    "            history.append(f\"Observation: {observation}\")\n",
    "\n",
    "        return \"\\n\".join(history)\n",
    "\n",
    "    def _format_tools(self) -> str:\n",
    "        \"\"\"Format available tools for the prompt\"\"\"\n",
    "        tool_descriptions = []\n",
    "        for name, tool in self.tools.items():\n",
    "            tool_descriptions.append(f\"- {name}: {tool.description}\")\n",
    "\n",
    "        tool_descriptions.append(\n",
    "            \"- final_answer: Use this when you have the final answer to the task\"\n",
    "        )\n",
    "        return \"\\n\".join(tool_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = CalculatorTool()\n",
    "tools = [calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(system_message, prompt, temperature=0.7):\n",
    "    # This would normally call your LLM\n",
    "    # For testing, return a dummy response\n",
    "    if \"plan\" in prompt.lower():\n",
    "        return \"\"\"\n",
    "        1. calculator 2+2\n",
    "        2. calculator (4)*3\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return \"\"\"\n",
    "        Thought: I need to calculate 2+2 first\n",
    "        Action: calculator 2+2\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_agent = ReactAgent(tools=tools, model=model_fn, max_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "React Agent Result: None\n"
     ]
    }
   ],
   "source": [
    "react_result = react_agent.run(\"Calculate 2+2 and then multiply by 3\")\n",
    "print(f\"React Agent Result: {react_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlannerAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    A planner-executor agent that first creates a plan, then executes it step by step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tools: List[Tool],\n",
    "        model: callable,\n",
    "        max_steps: int = 15,\n",
    "        temperature: float = 0.7,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            tools=tools,\n",
    "            model=model,\n",
    "            max_steps=max_steps,\n",
    "            name=\"planner_agent\",\n",
    "            description=\"An agent that creates a plan and then executes it\",\n",
    "        )\n",
    "        self.temperature = temperature\n",
    "        self.plan = []\n",
    "        self.current_plan_step = 0\n",
    "\n",
    "    def generate_action(self, task: str) -> dict:\n",
    "        \"\"\"\n",
    "        Generate next action based on the plan or create a plan\n",
    "\n",
    "        Args:\n",
    "            task (str): The task to complete\n",
    "\n",
    "        Returns:\n",
    "            dict: Action dictionary\n",
    "        \"\"\"\n",
    "        # If no plan exists, create one\n",
    "        if not self.plan:\n",
    "            self.plan = self._create_plan(task)\n",
    "            logger.info(f\"Created plan with {len(self.plan)} steps\")\n",
    "\n",
    "        # If we've completed the plan, return final answer\n",
    "        if self.current_plan_step >= len(self.plan):\n",
    "            return {\"tool\": \"final_answer\", \"input\": self._generate_final_answer(task)}\n",
    "\n",
    "        # Get the current plan step\n",
    "        current_step = self.plan[self.current_plan_step]\n",
    "        self.current_plan_step += 1\n",
    "\n",
    "        # Parse the tool and input\n",
    "        try:\n",
    "            parts = current_step.split(maxsplit=1)\n",
    "            if len(parts) < 2:\n",
    "                raise AgentError(f\"Invalid plan step: {current_step}\")\n",
    "\n",
    "            tool_name = parts[0]\n",
    "            tool_input = parts[1]\n",
    "\n",
    "            return {\n",
    "                \"thought\": f\"Executing plan step {self.current_plan_step}: {current_step}\",\n",
    "                \"tool\": tool_name,\n",
    "                \"input\": tool_input,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to parse plan step: {str(e)}\")\n",
    "            return {\n",
    "                \"tool\": \"error\",\n",
    "                \"input\": f\"Error in plan step {self.current_plan_step}: {str(e)}\",\n",
    "            }\n",
    "\n",
    "    def execute_action(self, action: dict) -> Any:\n",
    "        \"\"\"\n",
    "        Execute the action from the plan\n",
    "\n",
    "        Args:\n",
    "            action (dict): Action to execute\n",
    "\n",
    "        Returns:\n",
    "            Any: Result of the action\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tool_name = action[\"tool\"]\n",
    "            tool_input = action[\"input\"]\n",
    "\n",
    "            if tool_name == \"final_answer\":\n",
    "                return {\"observation\": tool_input, \"status\": \"final_answer\"}\n",
    "\n",
    "            if tool_name == \"error\":\n",
    "                return {\"observation\": tool_input, \"status\": \"error\"}\n",
    "\n",
    "            if tool_name not in self.tools:\n",
    "                return {\n",
    "                    \"observation\": f\"Error: Unknown tool '{tool_name}'\",\n",
    "                    \"status\": \"error\",\n",
    "                }\n",
    "\n",
    "            tool = self.tools[tool_name]\n",
    "            result = tool.execute(tool_input)\n",
    "\n",
    "            return {\"observation\": str(result), \"status\": \"success\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Action execution failed: {str(e)}\")\n",
    "            return {\"observation\": f\"Error: {str(e)}\", \"status\": \"error\"}\n",
    "\n",
    "    def is_final_answer(self, result: Any) -> bool:\n",
    "        \"\"\"Check if the result is a final answer\"\"\"\n",
    "        if isinstance(result, dict) and \"status\" in result:\n",
    "            return result[\"status\"] == \"final_answer\"\n",
    "        return False\n",
    "\n",
    "    def _create_plan(self, task: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Create a plan for completing the task\n",
    "\n",
    "        Args:\n",
    "            task (str): The task to plan for\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of plan steps\n",
    "        \"\"\"\n",
    "        system_prompt = \"\"\"You are a planning AI that creates step-by-step plans.\n",
    "Your task is to break down complex problems into a series of tool-using steps.\n",
    "Each step should use one tool and specify the input to that tool.\n",
    "Format each step as: tool_name input_parameters\"\"\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Task: {task}\n",
    "\n",
    "Available tools:\n",
    "{self._format_tools()}\n",
    "\n",
    "Create a detailed step-by-step plan to solve this task.\n",
    "The plan should be a numbered list where each step uses a tool.\n",
    "Format each step as: tool_name input_parameters\n",
    "\"\"\"\n",
    "\n",
    "        # Generate the plan\n",
    "        response = self.model(system_prompt, prompt, temperature=self.temperature)\n",
    "\n",
    "        # Parse the plan into steps\n",
    "        plan_steps = []\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "\n",
    "        for line in lines:\n",
    "            # Skip empty lines and lines without tool calls\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Remove step numbers and bullets\n",
    "            while line and not line[0].isalpha():\n",
    "                line = line[1:].strip()\n",
    "\n",
    "            # Remove step prefixes like \"Step 1: \"\n",
    "            if \":\" in line and line.split(\":\")[0].strip().lower().startswith(\"step\"):\n",
    "                line = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "            if line and \" \" in line:  # Ensure there's a tool and parameters\n",
    "                plan_steps.append(line)\n",
    "\n",
    "        return plan_steps\n",
    "\n",
    "    def _generate_final_answer(self, task: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a final answer based on the plan execution\n",
    "\n",
    "        Args:\n",
    "            task (str): The original task\n",
    "\n",
    "        Returns:\n",
    "            str: The final answer\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are an AI that summarizes results of a multi-step execution plan.\"\n",
    "        )\n",
    "\n",
    "        history = []\n",
    "        for step in self.memory.steps:\n",
    "            action = step[\"action\"]\n",
    "            result = step[\"result\"]\n",
    "\n",
    "            tool = action.get(\"tool\", \"\")\n",
    "            tool_input = action.get(\"input\", \"\")\n",
    "\n",
    "            observation = (\n",
    "                result.get(\"observation\", \"\")\n",
    "                if isinstance(result, dict)\n",
    "                else str(result)\n",
    "            )\n",
    "\n",
    "            history.append(f\"Step {step['step'] + 1}:\")\n",
    "            history.append(f\"Action: {tool} {tool_input}\")\n",
    "            history.append(f\"Result: {observation}\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Original task: {task}\n",
    "\n",
    "Execution history:\n",
    "{chr(10).join(history)}\n",
    "\n",
    "Provide a concise final answer to the original task.\n",
    "\"\"\"\n",
    "\n",
    "        # Generate the final answer\n",
    "        response = self.model(system_prompt, prompt, temperature=self.temperature)\n",
    "\n",
    "        return response.strip()\n",
    "\n",
    "    def _format_tools(self) -> str:\n",
    "        \"\"\"Format available tools for the prompt\"\"\"\n",
    "        tool_descriptions = []\n",
    "        for name, tool in self.tools.items():\n",
    "            tool_descriptions.append(f\"- {name}: {tool.description}\")\n",
    "\n",
    "        return \"\\n\".join(tool_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = PlannerAgent(tools=tools, model=model_fn, max_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-31 23:34:35.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_action\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mCreated plan with 2 steps\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner Agent Result: {'observation': 'Thought: I need to calculate 2+2 first\\n        Action: calculator 2+2', 'status': 'final_answer'}\n"
     ]
    }
   ],
   "source": [
    "planner_result = planner_agent.run(\"Calculate 2+2 and then multiply by 3\")\n",
    "print(f\"Planner Agent Result: {planner_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DummyLLM:\n",
    "    \"\"\"\n",
    "    A dummy LLM implementation that returns random responses\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, temperature: float = 0.7):\n",
    "        self.temperature = temperature\n",
    "        self._responses = [\n",
    "            \"I think we should use the calculator tool for this task.\",\n",
    "            \"Let me search through the available tools.\",\n",
    "            \"Based on my analysis, we should proceed step by step.\",\n",
    "            \"I recommend using the following approach...\",\n",
    "            \"The solution requires mathematical computation.\",\n",
    "            \"Let's break this problem down into smaller parts.\",\n",
    "        ]\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        system_message: Optional[str] = None,\n",
    "        temperature: Optional[float] = None,\n",
    "    ) -> Dict[str, Union[str, float]]:\n",
    "        \"\"\"\n",
    "        Generate a random response with metadata\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The input prompt\n",
    "            system_message (Optional[str]): System message to guide generation\n",
    "            temperature (Optional[float]): Override default temperature\n",
    "\n",
    "        Returns:\n",
    "            Dict containing response text and metadata\n",
    "        \"\"\"\n",
    "        # Use random confidence score between 0.3 and 0.9\n",
    "        confidence = random.uniform(0.3, 0.9)\n",
    "\n",
    "        return {\n",
    "            \"text\": random.choice(self._responses),\n",
    "            \"confidence\": confidence,\n",
    "            \"tokens_used\": random.randint(10, 50),\n",
    "            \"finish_reason\": \"stop\",\n",
    "        }\n",
    "\n",
    "    def batch_generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        system_message: Optional[str] = None,\n",
    "        temperature: Optional[float] = None,\n",
    "    ) -> List[Dict[str, Union[str, float]]]:\n",
    "        \"\"\"\n",
    "        Generate multiple random responses\n",
    "\n",
    "        Args:\n",
    "            prompts (List[str]): List of input prompts\n",
    "            system_message (Optional[str]): System message to guide generation\n",
    "            temperature (Optional[float]): Override default temperature\n",
    "\n",
    "        Returns:\n",
    "            List of response dictionaries\n",
    "        \"\"\"\n",
    "        return [\n",
    "            self.generate(prompt, system_message, temperature) for prompt in prompts\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
